{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b26d957",
   "metadata": {},
   "source": [
    "# AI-Powered Interview Assessment System\n",
    "\n",
    "## 1. Import Libraries & Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3054052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully pre-loaded NVIDIA libraries: libcublas.so.12\n",
      "Loading Whisper model (INT8 mode for lower VRAM usage)...\n",
      "Model loaded successfully (GPU/CUDA - INT8 Mode)\n",
      "Model loaded successfully (GPU/CUDA - INT8 Mode)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import ctypes\n",
    "import site\n",
    "import json\n",
    "import subprocess\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def force_load_nvidia_libs():\n",
    "    \"\"\"\n",
    "    Force load NVIDIA libraries (cublas & cudnn) into memory using ctypes.\n",
    "    This resolves LD_LIBRARY_PATH issues in Jupyter Notebook.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        site_packages = site.getsitepackages()\n",
    "        libs_loaded = []\n",
    "        \n",
    "        for sp in site_packages:\n",
    "            nvidia_dir = Path(sp) / \"nvidia\"\n",
    "            if not nvidia_dir.exists():\n",
    "                continue\n",
    "\n",
    "            targets = [\n",
    "                \"cublas/lib/libcublas.so.12\",\n",
    "                \"cudnn/lib/libcudnn_ops_infer.so.8\",\n",
    "                \"cudnn/lib/libcudnn_cnn_infer.so.8\" \n",
    "            ]\n",
    "            \n",
    "            for target in targets:\n",
    "                lib_path = list(nvidia_dir.glob(target))\n",
    "                if not lib_path:\n",
    "                     lib_path = list(nvidia_dir.glob(f\"*/lib/{Path(target).name}\"))\n",
    "                \n",
    "                if lib_path:\n",
    "                    try:\n",
    "                        ctypes.CDLL(str(lib_path[0]))\n",
    "                        libs_loaded.append(lib_path[0].name)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Warning: Failed to load {lib_path[0].name}: {e}\")\n",
    "\n",
    "        if libs_loaded:\n",
    "            print(f\"Successfully pre-loaded NVIDIA libraries: {', '.join(libs_loaded)}\")\n",
    "        else:\n",
    "            print(\"Warning: No NVIDIA libraries found in venv. Run 'pip install nvidia-cublas-cu12'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during library pre-load: {e}\")\n",
    "\n",
    "# Force load NVIDIA libraries before importing faster_whisper\n",
    "force_load_nvidia_libs()\n",
    "\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "# Setup directories\n",
    "TEMP_FOLDER = \"temp_interview_data\"\n",
    "VIDEO_FOLDER = \"vid\"\n",
    "os.makedirs(TEMP_FOLDER, exist_ok=True)\n",
    "os.makedirs(VIDEO_FOLDER, exist_ok=True)\n",
    "\n",
    "# Load Whisper model\n",
    "print(\"Loading Whisper model (INT8 mode for lower VRAM usage)...\")\n",
    "try:\n",
    "    model_stt = WhisperModel(\"large-v3\", device=\"cuda\", compute_type=\"int8\")\n",
    "    print(\"Model loaded successfully (GPU/CUDA - INT8 Mode)\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2913947d",
   "metadata": {},
   "source": [
    "## 2. Configure Input Data & Scoring Rubrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dae6a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input payload - interview data\n",
    "input_payload = {\n",
    "    \"data\": {\n",
    "        \"reviewChecklists\": {\n",
    "            \"interviews\": [\n",
    "                {\n",
    "                    \"positionId\": 1,\n",
    "                    \"question\": \"Can you share any specific challenges you faced while working on certification and how you overcame them?\",\n",
    "                    \"recordedVideoUrl\": \"https://drive.google.com/uc?id=1B8vb9lYz9LCCWpVdyglbDOgg-_ncndw8\" \n",
    "                },\n",
    "                {\n",
    "                    \"positionId\": 2,\n",
    "                    \"question\": \"Can you describe your experience with transfer learning in TensorFlow? How did it benefit your projects?\",\n",
    "                    \"recordedVideoUrl\": \"https://drive.google.com/uc?id=1VmUhGiGpSReiQlGabzqkehfPy8cKyZzR\"\n",
    "                },\n",
    "                {\n",
    "                    \"positionId\": 3,\n",
    "                    \"question\": \"Describe a complex TensorFlow model you have built and the steps you took to ensure its accuracy and efficiency.\",\n",
    "                    \"recordedVideoUrl\": \"https://drive.google.com/file/d/1b0R1W-FnZyziW4a4EUComRXkQhJF5gNV/view?usp=drive_link\"\n",
    "                },\n",
    "                {\n",
    "                    \"positionId\": 4,\n",
    "                    \"question\": \"Explain how to implement dropout in a TensorFlow model and the effect it has on training.\",\n",
    "                    \"recordedVideoUrl\": \"https://drive.google.com/file/d/1iUwQxAeJpB8oB7HjyyMpfq-c_lBIfyc4/view?usp=drive_link\"\n",
    "                },\n",
    "                {\n",
    "                    \"positionId\": 5,\n",
    "                    \"question\": \"Describe the process of building a convolutional neural network (CNN) using TensorFlow for image classification.\",\n",
    "                    \"recordedVideoUrl\": \"https://drive.google.com/file/d/1JE34UAK-NQMHyx4XPo-cmTBbZZ_tYj85/view?usp=drive_link\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"certification\": {\n",
    "            \"autoGraderProjectScore\": 100\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Scoring rubrics\n",
    "RUBRICS = {\n",
    "    1: \"Score 4 if detailed challenge & solution. Score 2 if general without detail. Score 0 if unanswered.\",\n",
    "    2: \"Score 4 if specific transfer learning experience & benefit shown. Score 2 if general definition only.\",\n",
    "    3: \"Score 4 if complex model architecture detailed. Score 2 if basic model mentioned.\",\n",
    "    4: \"Score 4 if dropout implementation & effect explained clearly. Score 2 if vague.\",\n",
    "    5: \"Score 4 if CNN building steps (layers, compile, train) detailed. Score 2 if steps missing.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddaebc6",
   "metadata": {},
   "source": [
    "## 3. Core Functions: Media Processing & AI Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89e12f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_media(file_id):\n",
    "    \"\"\"\n",
    "    Load video from vid folder and convert to WAV audio.\n",
    "    \n",
    "    Args:\n",
    "        file_id: Question ID number\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (audio_path, error_message)\n",
    "    \"\"\"\n",
    "    audio_path = os.path.join(TEMP_FOLDER, f\"{file_id}.wav\")\n",
    "    \n",
    "    # Check for video files with various formats and naming patterns\n",
    "    local_video_extensions = ['.mp4', '.webm', '.mkv', '.avi', '.mov']\n",
    "    video_path = None\n",
    "    \n",
    "    possible_names = [\n",
    "        f\"ans_{file_id}\",\n",
    "        f\"interview_question_{file_id}\",\n",
    "        f\"question_{file_id}\",\n",
    "        f\"{file_id}\"\n",
    "    ]\n",
    "    \n",
    "    for name in possible_names:\n",
    "        for ext in local_video_extensions:\n",
    "            potential_path = os.path.join(VIDEO_FOLDER, f\"{name}{ext}\")\n",
    "            if os.path.exists(potential_path):\n",
    "                video_path = potential_path\n",
    "                break\n",
    "        if video_path:\n",
    "            break\n",
    "    \n",
    "    if not video_path:\n",
    "        supported_formats = ', '.join(local_video_extensions)\n",
    "        return None, f\"Video for question #{file_id} not found in '{VIDEO_FOLDER}'. Supported formats: {supported_formats}\"\n",
    "\n",
    "    # Convert video to audio (WAV 16kHz Mono)\n",
    "    subprocess.run([\n",
    "        \"ffmpeg\", \"-i\", video_path, \n",
    "        \"-ar\", \"16000\", \"-ac\", \"1\", \n",
    "        \"-c:a\", \"pcm_s16le\", \"-y\", \"-vn\",\n",
    "        audio_path\n",
    "    ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    \n",
    "    if not os.path.exists(audio_path):\n",
    "        return None, f\"Failed to extract audio from {video_path}\"\n",
    "    \n",
    "    return audio_path, None\n",
    "\n",
    "\n",
    "def ask_ollama(question, answer_text, rubric_text):\n",
    "    \"\"\"\n",
    "    Send data to Ollama (Llama 3.1) for evaluation.\n",
    "    \n",
    "    Args:\n",
    "        question: Interview question\n",
    "        answer_text: Transcribed answer\n",
    "        rubric_text: Scoring rubric\n",
    "        \n",
    "    Returns:\n",
    "        dict: {\"score\": int, \"reason\": str}\n",
    "    \"\"\"\n",
    "    system_prompt = f\"\"\"\n",
    "    You are a Technical Interview Assessor. \n",
    "    Evaluate the candidate's answer based on the Rubric.\n",
    "    \n",
    "    Question: \"{question}\"\n",
    "    Rubric Rule: {rubric_text}\n",
    "    \n",
    "    You MUST output a JSON object with strictly these fields:\n",
    "    - \"score\": (integer 0-4)\n",
    "    - \"reason\": (string, max 2 sentences explaining the score)\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"Candidate Answer: {answer_text}\"\n",
    "\n",
    "    response = requests.post('http://localhost:11434/api/chat', json={\n",
    "        \"model\": \"llama3.1\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        \"format\": \"json\",\n",
    "        \"stream\": False\n",
    "    })\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return json.loads(response.json()['message']['content'])\n",
    "    else:\n",
    "        return {\"score\": 0, \"reason\": \"Error calling AI\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5aa391",
   "metadata": {},
   "source": [
    "## 4. Process All Interview Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4c27a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting assessment process...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing interviews:   0%|          | 0/5 [00:00<?, ?question/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Question 1] Video found, extracting audio...\n",
      "[Question 1] Transcribing audio...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing interviews:   0%|          | 0/5 [00:07<?, ?question/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Question 1] Transcript:  ok, share any specific challenges you faced while working on certification and ...\n",
      "[Question 1] Evaluating response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing interviews:  20%|██        | 1/5 [00:20<01:21, 20.28s/question]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Question 1] Score: 3/4 - The candidate provides specific examples of challenges faced during the certification process, including issues with accuracy and violation laws. However, the answer could be more detailed in terms of the impact and outcomes of their solutions.\n",
      "\n",
      "[Question 2] Video found, extracting audio...\n",
      "[Question 2] Transcribing audio...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing interviews:  20%|██        | 1/5 [00:36<01:21, 20.28s/question]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Question 2] Transcript:  can you describe your experience with transfer learning and time short flow how...\n",
      "[Question 2] Evaluating response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing interviews:  40%|████      | 2/5 [00:52<01:21, 27.04s/question]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Question 2] Score: 2/4 - The candidate provided a general definition of transfer learning in TensorFlow, but did not share any specific experience or project benefits. They mentioned some pre-trained models (e.g. VGG16, VGG19) and their applications, but the answer lacked concrete examples and details.\n",
      "\n",
      "[Question 3] Video found, extracting audio...\n",
      "[Question 3] Transcribing audio...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing interviews:  40%|████      | 2/5 [01:10<01:21, 27.04s/question]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Question 3] Transcript:  Describe a complex TensorFlow model you've built and the steps you took to ensu...\n",
      "[Question 3] Evaluating response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing interviews:  60%|██████    | 3/5 [01:25<00:59, 29.87s/question]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Question 3] Score: 3/4 - The candidate mentions a complex model architecture, specifically using Keras or TensorFlow for Celiac Disease Prediction. However, the details provided are somewhat limited and lack technical depth, preventing a higher score.\n",
      "\n",
      "[Question 4] Video found, extracting audio...\n",
      "[Question 4] Transcribing audio...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing interviews:  60%|██████    | 3/5 [01:48<00:59, 29.87s/question]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Question 4] Transcript:  Jelaskan bagaimana cara mengimplementasikan dropout di test on flow model dan t...\n",
      "[Question 4] Evaluating response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing interviews:  80%|████████  | 4/5 [02:06<00:34, 34.18s/question]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Question 4] Score: 2/4 - The candidate's answer is vague and lacks clarity in explaining the implementation of dropout in a TensorFlow model and its effect on training. They mention using dropout layers in a project, but fail to provide a clear explanation of how it works or its benefits.\n",
      "\n",
      "[Question 5] Video found, extracting audio...\n",
      "[Question 5] Transcribing audio...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing interviews:  80%|████████  | 4/5 [02:32<00:34, 34.18s/question]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Question 5] Transcript:  Describe the process of building or configuring or using software image as fict...\n",
      "[Question 5] Evaluating response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing interviews: 100%|██████████| 5/5 [02:50<00:00, 34.10s/question]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Question 5] Score: 2/4 - The candidate's answer is partially correct as they mention some steps in building a CNN, but it lacks detail. They outline the basic process of splitting the dataset and using data augmentation, but skip important details such as compiling the model, selecting an optimizer and loss function, and training the model.\n",
      "\n",
      "\n",
      "All questions processed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "interview_results = []\n",
    "total_interview_score = 0\n",
    "interviews_data = input_payload['data']['reviewChecklists']['interviews']\n",
    "transcript_details = []\n",
    "\n",
    "print(\"Starting assessment process...\\n\")\n",
    "\n",
    "# Process each interview question with progress bar\n",
    "for item in tqdm(interviews_data, desc=\"Processing interviews\", unit=\"question\"):\n",
    "    q_id = item['positionId']\n",
    "    question = item['question']\n",
    "    \n",
    "    # Step 1: Load video and extract audio\n",
    "    audio_file, error = process_media(q_id)\n",
    "    if error:\n",
    "        tqdm.write(f\"[Question {q_id}] {error}\")\n",
    "        continue\n",
    "    \n",
    "    tqdm.write(f\"[Question {q_id}] Video found, extracting audio...\")\n",
    "        \n",
    "    # Step 2: Transcribe audio using Whisper\n",
    "    tqdm.write(f\"[Question {q_id}] Transcribing audio...\")\n",
    "    segments, _ = model_stt.transcribe(audio_file, beam_size=5, language=None)\n",
    "    transcript_text = \" \".join([s.text for s in segments])\n",
    "    tqdm.write(f\"[Question {q_id}] Transcript: {transcript_text[:80]}...\")\n",
    "    \n",
    "    # Step 3: Evaluate using Ollama AI\n",
    "    tqdm.write(f\"[Question {q_id}] Evaluating response...\")\n",
    "    rubric_rule = RUBRICS.get(q_id, \"General assessment\")\n",
    "    ai_result = ask_ollama(question, transcript_text, rubric_rule)\n",
    "    \n",
    "    # Step 4: Save results\n",
    "    result_obj = {\n",
    "        \"id\": q_id,\n",
    "        \"score\": ai_result['score'],\n",
    "        \"reason\": ai_result['reason']\n",
    "    }\n",
    "    interview_results.append(result_obj)\n",
    "    total_interview_score += ai_result['score']\n",
    "    \n",
    "    # Save transcript details\n",
    "    transcript_details.append({\n",
    "        \"video_id\": q_id,\n",
    "        \"question\": question,\n",
    "        \"answer\": transcript_text,\n",
    "        \"score\": ai_result['score'],\n",
    "        \"reason\": ai_result['reason']\n",
    "    })\n",
    "    \n",
    "    tqdm.write(f\"[Question {q_id}] Score: {ai_result['score']}/4 - {ai_result['reason']}\\n\")\n",
    "\n",
    "print(\"\\nAll questions processed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad9cf2e",
   "metadata": {},
   "source": [
    "## 5. Generate Final Results & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "587ac620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ASSESSMENT RESULTS\n",
      "================================================================================\n",
      "{\n",
      "  \"assessorProfile\": {\n",
      "    \"id\": 1,\n",
      "    \"name\": \"AI Auto-Assessor\",\n",
      "    \"photoUrl\": \"https://ui-avatars.com/api/?name=AI\"\n",
      "  },\n",
      "  \"decision\": \"PASSED\",\n",
      "  \"reviewedAt\": \"2025-11-30 10:00:00\",\n",
      "  \"scoresOverview\": {\n",
      "    \"project\": 100,\n",
      "    \"interview\": 12,\n",
      "    \"total\": 80.0\n",
      "  },\n",
      "  \"reviewChecklistResult\": {\n",
      "    \"project\": [],\n",
      "    \"interviews\": {\n",
      "      \"minScore\": 0,\n",
      "      \"maxScore\": 4,\n",
      "      \"scores\": [\n",
      "        {\n",
      "          \"id\": 1,\n",
      "          \"score\": 3,\n",
      "          \"reason\": \"The candidate provides specific examples of challenges faced during the certification process, including issues with accuracy and violation laws. However, the answer could be more detailed in terms of the impact and outcomes of their solutions.\"\n",
      "        },\n",
      "        {\n",
      "          \"id\": 2,\n",
      "          \"score\": 2,\n",
      "          \"reason\": \"The candidate provided a general definition of transfer learning in TensorFlow, but did not share any specific experience or project benefits. They mentioned some pre-trained models (e.g. VGG16, VGG19) and their applications, but the answer lacked concrete examples and details.\"\n",
      "        },\n",
      "        {\n",
      "          \"id\": 3,\n",
      "          \"score\": 3,\n",
      "          \"reason\": \"The candidate mentions a complex model architecture, specifically using Keras or TensorFlow for Celiac Disease Prediction. However, the details provided are somewhat limited and lack technical depth, preventing a higher score.\"\n",
      "        },\n",
      "        {\n",
      "          \"id\": 4,\n",
      "          \"score\": 2,\n",
      "          \"reason\": \"The candidate's answer is vague and lacks clarity in explaining the implementation of dropout in a TensorFlow model and its effect on training. They mention using dropout layers in a project, but fail to provide a clear explanation of how it works or its benefits.\"\n",
      "        },\n",
      "        {\n",
      "          \"id\": 5,\n",
      "          \"score\": 2,\n",
      "          \"reason\": \"The candidate's answer is partially correct as they mention some steps in building a CNN, but it lacks detail. They outline the basic process of splitting the dataset and using data augmentation, but skip important details such as compiling the model, selecting an optimizer and loss function, and training the model.\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"transcriptDetails\": [\n",
      "    {\n",
      "      \"video_id\": 1,\n",
      "      \"question\": \"Can you share any specific challenges you faced while working on certification and how you overcame them?\",\n",
      "      \"answer\": \" ok, share any specific challenges you faced while working on certification and how you overcome them  ah, ok, actually for the challenges, there are some challenges when i took the certification  especially for the project i mentioned that i already working with it  the first one is actually to meet the specific accuracy or violation laws for the evaluation matrix  and actually that just need to take some trial and error with different architecture  for example like  we can  try to add more layer, more neurons, changes the neurons  or even i also apply the drop out layer  so it really helps with the validation laws to become more lower  and i think that's one of the biggest challenges that i have while  working on this certification\",\n",
      "      \"score\": 3,\n",
      "      \"reason\": \"The candidate provides specific examples of challenges faced during the certification process, including issues with accuracy and violation laws. However, the answer could be more detailed in terms of the impact and outcomes of their solutions.\"\n",
      "    },\n",
      "    {\n",
      "      \"video_id\": 2,\n",
      "      \"question\": \"Can you describe your experience with transfer learning in TensorFlow? How did it benefit your projects?\",\n",
      "      \"answer\": \" can you describe your experience with transfer learning and time short flow how do you benefit  the projects ah okay uh about transfer learning is actually uh we use existing train model from  attention flow for example like uh vgc 16 vg 19 right uh especially uh for for some cases  uh that we need to use deep learning using keras applications uh for example like image  classification we can use transfer learning models which is that's already trained model with  exceptionally high accuracy high performance uh yeah even though it's trained with different  data sets  but it will it really helps uh to improve uh our model performance uh model accuracy model loss  and you know for example like mobile net uh vg19 vgg 16 yeah efficient net  it will help to improve our our models comparing to the one  you use a traditional cnn model yeah cnn model with the convolutional 2d yeah max pooling and  yeah it it's it's quite good actually to use transfer learning it really helps with our  model performance to improve our model performance\",\n",
      "      \"score\": 2,\n",
      "      \"reason\": \"The candidate provided a general definition of transfer learning in TensorFlow, but did not share any specific experience or project benefits. They mentioned some pre-trained models (e.g. VGG16, VGG19) and their applications, but the answer lacked concrete examples and details.\"\n",
      "    },\n",
      "    {\n",
      "      \"video_id\": 3,\n",
      "      \"question\": \"Describe a complex TensorFlow model you have built and the steps you took to ensure its accuracy and efficiency.\",\n",
      "      \"answer\": \" Describe a complex TensorFlow model you've built and the steps you took to ensure its accuracy and efficiency  Complex TensorFlow model you've built and steps you took to ensure its accuracy  I will take one of my previous project that I also use Keras or TensorFlow model  It is about Celiac Disease Prediction  This is also I use the research project for my undergraduate thesis for my Scripc  I use this model, it's quite challenging even though it's achieved high accuracy  With some dense layer, with some dropout layer  And trial and error also with the callback function, with the neurons  But the problem is it's not easy to use this model  The problem is the dataset is not balanced  So it has the imbalanced class datasets  And the approach that I use is to just to use the technique called smooth and synthetic oversampling technique  With edited nearest neighbor  Which is basically it's just oversampling and undersampling  the datasets  It helps with the accuracy\",\n",
      "      \"score\": 3,\n",
      "      \"reason\": \"The candidate mentions a complex model architecture, specifically using Keras or TensorFlow for Celiac Disease Prediction. However, the details provided are somewhat limited and lack technical depth, preventing a higher score.\"\n",
      "    },\n",
      "    {\n",
      "      \"video_id\": 4,\n",
      "      \"question\": \"Explain how to implement dropout in a TensorFlow model and the effect it has on training.\",\n",
      "      \"answer\": \" Jelaskan bagaimana cara mengimplementasikan dropout di test on flow model dan test on training  Sebelumnya saya juga mengimplementasikan dropout layer  Juga di project exhibition dalam sertifikasi ini  Dan kita bisa menambahkan dropout layer  Contohnya, jika saya tidak salah, saya sudah menggunakan dropout layer di image classification  German traffic something, jika saya tidak salah  Saya sudah menggunakan dropout layer ini  Di...  Di...  Di...  Tidak di akhir  Di...  Di tengah layer  Jadi, ada layer flatten  Bukan flatten, layer convolutional  Dan layer flatten  Dan saya menggunakan layer dropout  Yang saya gunakan dengan rate 0.2 atau 0.5 jika saya tidak salah  Dan layer dense dan layer output terakhir  Ini adalah efeknya...  Ini sangat membantu untuk...  Kebaikan akurasi kita dan turunkan keterangan validation kita  Dengan membalaskan beberapa layer sebelumnya  Ya, misalnya kita memiliki layer dense 64  Dan layer berikutnya, kita mengimplementasikan layer dropout dengan rate 0.5  akan berubah secara random setiap epoch dari layer dance yang sebelumnya\",\n",
      "      \"score\": 2,\n",
      "      \"reason\": \"The candidate's answer is vague and lacks clarity in explaining the implementation of dropout in a TensorFlow model and its effect on training. They mention using dropout layers in a project, but fail to provide a clear explanation of how it works or its benefits.\"\n",
      "    },\n",
      "    {\n",
      "      \"video_id\": 5,\n",
      "      \"question\": \"Describe the process of building a convolutional neural network (CNN) using TensorFlow for image classification.\",\n",
      "      \"answer\": \" Describe the process of building or configuring or using software image as fiction  okay the CNN one right so at the first time of course we need to make sure  there are split the image folder split it for for each class okay and then we  can use\\u30d2\\u0627\\u0631\\u0633 Image Dataset to split the training and the validation dataset  all right yeah of course we can use another another set which is the test  dataset yeah but yeah okay the next one we can we can just maybe we need to  implement also the Xiaobai data set  data image data augmentation tool to make our data set more  veritive right for example like we can rotate we can zoom it we can crop it  yeah and yeah the last thing yeah of course we we can build our chain model  with the conventional 2D specify the filters the kernel size the LR activation  force the inputs input shape for the first layer and then we can apply the  max pooling 2D yeah and the next layer we can just use  conventional 2D max pooling and whatever it is and after that we apply  the flatten layer and dropout layer if you want and the last thing don't forget  to use the dense layer right for the output  like the last of\",\n",
      "      \"score\": 2,\n",
      "      \"reason\": \"The candidate's answer is partially correct as they mention some steps in building a CNN, but it lacks detail. They outline the basic process of splitting the dataset and using data augmentation, but skip important details such as compiling the model, selecting an optimizer and loss function, and training the model.\"\n",
      "    }\n",
      "  ],\n",
      "  \"Overall notes\": \"Assessment completed automatically via Local AI. Total Score: 80.0\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "DETAILED TRANSCRIPT & SCORING\n",
      "================================================================================\n",
      "\n",
      "VIDEO #1\n",
      "Question: Can you share any specific challenges you faced while working on certification and how you overcame them?\n",
      "Answer:  ok, share any specific challenges you faced while working on certification and how you overcome them  ah, ok, actually for the challenges, there are some challenges when i took the certification  especially for the project i mentioned that i already working with it  the first one is actually to meet the specific accuracy or violation laws for the evaluation matrix  and actually that just need to take some trial and error with different architecture  for example like  we can  try to add more layer, more neurons, changes the neurons  or even i also apply the drop out layer  so it really helps with the validation laws to become more lower  and i think that's one of the biggest challenges that i have while  working on this certification\n",
      "Score: 3/4\n",
      "Reason: The candidate provides specific examples of challenges faced during the certification process, including issues with accuracy and violation laws. However, the answer could be more detailed in terms of the impact and outcomes of their solutions.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "VIDEO #2\n",
      "Question: Can you describe your experience with transfer learning in TensorFlow? How did it benefit your projects?\n",
      "Answer:  can you describe your experience with transfer learning and time short flow how do you benefit  the projects ah okay uh about transfer learning is actually uh we use existing train model from  attention flow for example like uh vgc 16 vg 19 right uh especially uh for for some cases  uh that we need to use deep learning using keras applications uh for example like image  classification we can use transfer learning models which is that's already trained model with  exceptionally high accuracy high performance uh yeah even though it's trained with different  data sets  but it will it really helps uh to improve uh our model performance uh model accuracy model loss  and you know for example like mobile net uh vg19 vgg 16 yeah efficient net  it will help to improve our our models comparing to the one  you use a traditional cnn model yeah cnn model with the convolutional 2d yeah max pooling and  yeah it it's it's quite good actually to use transfer learning it really helps with our  model performance to improve our model performance\n",
      "Score: 2/4\n",
      "Reason: The candidate provided a general definition of transfer learning in TensorFlow, but did not share any specific experience or project benefits. They mentioned some pre-trained models (e.g. VGG16, VGG19) and their applications, but the answer lacked concrete examples and details.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "VIDEO #3\n",
      "Question: Describe a complex TensorFlow model you have built and the steps you took to ensure its accuracy and efficiency.\n",
      "Answer:  Describe a complex TensorFlow model you've built and the steps you took to ensure its accuracy and efficiency  Complex TensorFlow model you've built and steps you took to ensure its accuracy  I will take one of my previous project that I also use Keras or TensorFlow model  It is about Celiac Disease Prediction  This is also I use the research project for my undergraduate thesis for my Scripc  I use this model, it's quite challenging even though it's achieved high accuracy  With some dense layer, with some dropout layer  And trial and error also with the callback function, with the neurons  But the problem is it's not easy to use this model  The problem is the dataset is not balanced  So it has the imbalanced class datasets  And the approach that I use is to just to use the technique called smooth and synthetic oversampling technique  With edited nearest neighbor  Which is basically it's just oversampling and undersampling  the datasets  It helps with the accuracy\n",
      "Score: 3/4\n",
      "Reason: The candidate mentions a complex model architecture, specifically using Keras or TensorFlow for Celiac Disease Prediction. However, the details provided are somewhat limited and lack technical depth, preventing a higher score.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "VIDEO #4\n",
      "Question: Explain how to implement dropout in a TensorFlow model and the effect it has on training.\n",
      "Answer:  Jelaskan bagaimana cara mengimplementasikan dropout di test on flow model dan test on training  Sebelumnya saya juga mengimplementasikan dropout layer  Juga di project exhibition dalam sertifikasi ini  Dan kita bisa menambahkan dropout layer  Contohnya, jika saya tidak salah, saya sudah menggunakan dropout layer di image classification  German traffic something, jika saya tidak salah  Saya sudah menggunakan dropout layer ini  Di...  Di...  Di...  Tidak di akhir  Di...  Di tengah layer  Jadi, ada layer flatten  Bukan flatten, layer convolutional  Dan layer flatten  Dan saya menggunakan layer dropout  Yang saya gunakan dengan rate 0.2 atau 0.5 jika saya tidak salah  Dan layer dense dan layer output terakhir  Ini adalah efeknya...  Ini sangat membantu untuk...  Kebaikan akurasi kita dan turunkan keterangan validation kita  Dengan membalaskan beberapa layer sebelumnya  Ya, misalnya kita memiliki layer dense 64  Dan layer berikutnya, kita mengimplementasikan layer dropout dengan rate 0.5  akan berubah secara random setiap epoch dari layer dance yang sebelumnya\n",
      "Score: 2/4\n",
      "Reason: The candidate's answer is vague and lacks clarity in explaining the implementation of dropout in a TensorFlow model and its effect on training. They mention using dropout layers in a project, but fail to provide a clear explanation of how it works or its benefits.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "VIDEO #5\n",
      "Question: Describe the process of building a convolutional neural network (CNN) using TensorFlow for image classification.\n",
      "Answer:  Describe the process of building or configuring or using software image as fiction  okay the CNN one right so at the first time of course we need to make sure  there are split the image folder split it for for each class okay and then we  can useヒارس Image Dataset to split the training and the validation dataset  all right yeah of course we can use another another set which is the test  dataset yeah but yeah okay the next one we can we can just maybe we need to  implement also the Xiaobai data set  data image data augmentation tool to make our data set more  veritive right for example like we can rotate we can zoom it we can crop it  yeah and yeah the last thing yeah of course we we can build our chain model  with the conventional 2D specify the filters the kernel size the LR activation  force the inputs input shape for the first layer and then we can apply the  max pooling 2D yeah and the next layer we can just use  conventional 2D max pooling and whatever it is and after that we apply  the flatten layer and dropout layer if you want and the last thing don't forget  to use the dense layer right for the output  like the last of\n",
      "Score: 2/4\n",
      "Reason: The candidate's answer is partially correct as they mention some steps in building a CNN, but it lacks detail. They outline the basic process of splitting the dataset and using data augmentation, but skip important details such as compiling the model, selecting an optimizer and loss function, and training the model.\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate final scores\n",
    "project_score = input_payload['data']['certification']['autoGraderProjectScore']\n",
    "interview_score_scaled = (total_interview_score / 20) * 100\n",
    "final_total_score = (project_score + interview_score_scaled) / 2\n",
    "\n",
    "# Determine pass/fail decision\n",
    "decision = \"PASSED\" if final_total_score >= 75 else \"Need Human Review\"\n",
    "\n",
    "# Build final JSON output\n",
    "final_output = {\n",
    "    \"assessorProfile\": {\n",
    "        \"id\": 1,\n",
    "        \"name\": \"AI Auto-Assessor\",\n",
    "        \"photoUrl\": \"https://ui-avatars.com/api/?name=AI\"\n",
    "    },\n",
    "    \"decision\": decision,\n",
    "    \"reviewedAt\": \"2025-11-30 10:00:00\",\n",
    "    \"scoresOverview\": {\n",
    "        \"project\": project_score,\n",
    "        \"interview\": total_interview_score,\n",
    "        \"total\": final_total_score\n",
    "    },\n",
    "    \"reviewChecklistResult\": {\n",
    "        \"project\": [],\n",
    "        \"interviews\": {\n",
    "            \"minScore\": 0,\n",
    "            \"maxScore\": 4,\n",
    "            \"scores\": interview_results\n",
    "        }\n",
    "    },\n",
    "    \"transcriptDetails\": transcript_details,\n",
    "    \"Overall notes\": f\"Assessment completed automatically via Local AI. Total Score: {final_total_score}\"\n",
    "}\n",
    "\n",
    "# Save to JSON file\n",
    "with open('hasil_penilaian_final.json', 'w') as f:\n",
    "    json.dump(final_output, f, indent=2)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ASSESSMENT RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(json.dumps(final_output, indent=2))\n",
    "\n",
    "# Display detailed transcript and scoring\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DETAILED TRANSCRIPT & SCORING\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "for detail in transcript_details:\n",
    "    print(f\"VIDEO #{detail['video_id']}\")\n",
    "    print(f\"Question: {detail['question']}\")\n",
    "    print(f\"Answer: {detail['answer']}\")\n",
    "    print(f\"Score: {detail['score']}/4\")\n",
    "    print(f\"Reason: {detail['reason']}\")\n",
    "    print(\"-\" * 80 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
